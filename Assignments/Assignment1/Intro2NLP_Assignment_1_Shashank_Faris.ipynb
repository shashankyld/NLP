{"cells":[{"cell_type":"markdown","id":"5a325897","metadata":{"id":"5a325897"},"source":["# Introduction to Natural Language Processing: Assignment 1\n","\n","In this assignment we'll practice tokenization, lemmatization and stemming\n","\n","- Please comment your code\n","- Submissions are due Thursday at 23:59 and should be submitted **ONLY** on eCampus: **Assignmnets >> Student Submissions >> Assignment 1 (Deadline: 14.11.2023, at 23:59)**\n","- Name the file aproppriately \"Assignment_1_\\<Your_Name\\>.ipynb\".\n","- Please submit **ONLY** the Jupyter Notebook file.\n","- Please use relative path; Your code should work on my computer if the Jupyter Notebook and the file are both in the same directory.\n","\n","Example: file_name = lemmatization-en.txt >> **DON'T use:** /Users/ComputerName/Username/Documents/.../lemmatization-en.txt"]},{"cell_type":"markdown","id":"0cd8bf33","metadata":{"id":"0cd8bf33"},"source":["### Task 1.1 (3 points)\n","\n","Write a function `extract_words_tokens(any_string)` that takes a string as input and returns two numbers:\n","1. num_words: The number of words in string\n","2. num_tokens: The number of tokens in string (Please use the character-based tokenization.)\n","\n","**Hint:** The string can be a single word or a sentence and\n"," can contain some special charecters, such as: \"!\", \",\", \":\""]},{"cell_type":"code","execution_count":null,"id":"f14f3124","metadata":{"id":"f14f3124"},"outputs":[],"source":["def extract_words_tokens(any_string):\n","    #here comes your code\n","    return(print(any_string, \":\", \"num_words:\", num_words, \"and\", \"num_tokens:\", num_tokens, \"respectively\"))"]},{"cell_type":"markdown","id":"a4b05add","metadata":{"id":"a4b05add"},"source":["### Task 1.2 (4 points)\n","\n","Write a function `lemmatize(any_string, file_name)` that takes as input any string and a file-name: `lemmatization-en.txt` (please download the file [here](https://github.com/michmech/lemmatization-lists/blob/master/lemmatization-en.txt). It's a tab separated corpus) and returns a dictionary with all words as keys and the lemma of the words as values.\n","\n","**Hint:** To tokenize the string, please use the whitespace as the seperator. The string doesn't contain any special characters."]},{"cell_type":"code","execution_count":null,"id":"a12f48ff","metadata":{"id":"a12f48ff"},"outputs":[],"source":["def lemmatize(any_string, file_name):\n","    #here comes your code\n","    return(print(dictionary_of_lemmatized_words))"]},{"cell_type":"markdown","id":"f266bdc4","metadata":{"id":"f266bdc4"},"source":["### Task 1.3 (3 points)\n","\n","Write a function `stemmer(string)` that takes a string as input and returns a string conaining only its stem.\n","\n","Create rules for the following forms of the verbs, Here is one example:\n","\n","- (Infinitive form) >> study - studi\n","- (Present simple tense: Third person) >> studies - studi\n","- (Continuous tense) >> studying - studi\n","- (Past simple tense) >> studied - studi\n","\n","**Hint:** The string can be a single word or a sentence and\n"," can contain some special charecters, such as: \"!\", \",\", \":\""]},{"cell_type":"code","execution_count":null,"id":"0b5c587b","metadata":{"id":"0b5c587b"},"outputs":[],"source":["def stemmer(any_string):\n","    #here comes your code\n","    return(print(stemmed_string))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":5}

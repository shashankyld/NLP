{"cells":[{"cell_type":"markdown","id":"92073528","metadata":{"id":"92073528"},"source":["# Introduction to Natural Language Processing: Assignment 2\n","\n","In this exercise we'll practice training and testing classifiers.\n","\n","- You can use any built-in Python packages, scikit-learn and Pandas.\n","- Please comment your code\n","- Submissions are due Thursday at 23:59 and should be submitted **ONLY** on eCampus: **Assignmnets >> Student Submissions >> Assignment 2 (Deadline: 21.11.2023, at 23:59)**\n","- Name the file aproppriately \"Assignment_2_\\<Your_Name\\>.ipynb\".\n","- Please use relative paths, your code should run on my computer if the notebook and the file are both in the same directory.\n","\n","Example: file_name = polarity.txt >> **DON'T use:** /Users/ComputerName/Username/Documents/.../polarity.txt"]},{"cell_type":"markdown","id":"7ef5be54","metadata":{"id":"7ef5be54"},"source":["### Task 1.1 (2 point)\n","\n","Create a DataFrame using the `polarity.txt` file and give name to the columns appropriately. (e.g., \"Text\", \"Label\")"]},{"cell_type":"code","execution_count":228,"id":"a259fbec","metadata":{"id":"a259fbec"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>polarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>15</th>\n","      <td>the most significant tension of _election_ is ...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>whatever . . . skip</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>one thing that's been bothering me since i've ...</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>critique : a mind-fuck movie for the teen gene...</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>witherspoon is a revelation .</td>\n","      <td>pos</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 text polarity\n","15  the most significant tension of _election_ is ...      pos\n","70                               whatever . . . skip       neg\n","31  one thing that's been bothering me since i've ...      pos\n","44  critique : a mind-fuck movie for the teen gene...      neg\n","28                     witherspoon is a revelation .       pos"]},"execution_count":228,"metadata":{},"output_type":"execute_result"}],"source":["#here comes your code\n","import pandas as pd\n","\n","df = pd.read_csv(\"polarity.txt\", sep='\\t', header=None)\n","df.columns = [\"text\", \"polarity\"]\n","df.sample(5)"]},{"cell_type":"markdown","id":"7b505bc8","metadata":{"id":"7b505bc8"},"source":["### Task 1.2 (2 point)\n","\n","Create a new column for the DataFrame that contains labels converted to numerical values instead of strings using the function: `apply()` and drop the original column afterwards.\n","\n","Hint: The numarical values can be any meaningful values, e.g., pos >> 1 and neg >> 0"]},{"cell_type":"code","execution_count":229,"id":"0b671658","metadata":{"id":"0b671658"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>polarity</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>40</th>\n","      <td>they get into an accident .</td>\n","      <td>neg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>there is an extraordinary amount of sexuality ...</td>\n","      <td>pos</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>there are dreams , there are characters coming...</td>\n","      <td>neg</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>one thing that's been bothering me since i've ...</td>\n","      <td>pos</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>do we really need to see it over and over agai...</td>\n","      <td>neg</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 text polarity  labels\n","40                       they get into an accident .       neg       0\n","32  there is an extraordinary amount of sexuality ...      pos       1\n","50  there are dreams , there are characters coming...      neg       0\n","31  one thing that's been bothering me since i've ...      pos       1\n","60  do we really need to see it over and over agai...      neg       0"]},"execution_count":229,"metadata":{},"output_type":"execute_result"}],"source":["# here comes your code\n","# Custom funtion that is applied to each element\n","def numberize(polarity):\n","    if polarity == \"pos\":\n","        return 1\n","    else: \n","        return 0\n","\n","df[\"labels\"] = df[\"polarity\"].apply(numberize)\n","df.sample(5)"]},{"cell_type":"markdown","id":"53dcdd4c","metadata":{"id":"53dcdd4c"},"source":["### Task 2 (8 points)\n","\n","Write a function `create_count_and_probability` that takes a file (`corpus.txt`) as input and returns a csv file as output containing three columns:\n","1. Text\n","2. Count_Vector\n","3. Probability\n","\n","Example:\n","\n","For the line: `This document is the second document.`\n","\n","The row in the csv file should contain:\n","`This document is the second document.`   `[0,2,0,1,0,1,1,0,1]`   `[1/6, 2/6, 1/6, 1/6, 1/6, 2/6]`\n","\n","**Note**:\n","\n","1. You should define your own function and not use e.g., CountVectorizer() which gives you the `count vector`, directly.\n","\n","2. You can either use the whitespace in `split` as the seperator or use the `Regular Expression (re)` to extract the words, as follows:\n","\n","```\n","import re\n","TEXT = \"Hey, - How are you doing today!?\"\n","words_list = re.findall(r\"[\\w']+\", TEXT)\n","print(words_list)\n","```\n","\n","3. To count the words, you can use e.g., the library: `collections`, more specifically `Counter`.\n","\n","4. Please don't upload the output file. Your function should generate the file."]},{"cell_type":"code","execution_count":230,"id":"a1a09321","metadata":{"id":"a1a09321"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>count_vector</th>\n","      <th>probability</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>This document is a sample document.</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, ...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>In this document, we have repeated words.</td>\n","      <td>[1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, ...</td>\n","      <td>[0.14285714285714285, 0.0, 0.14285714285714285...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Repeated words can help us understand word fre...</td>\n","      <td>[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.1...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Can you identify the repeated words in this do...</td>\n","      <td>[0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n","      <td>[0.0, 0.1111111111111111, 0.0, 0.1111111111111...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  \\\n","0                This document is a sample document.   \n","1          In this document, we have repeated words.   \n","2  Repeated words can help us understand word fre...   \n","3  Can you identify the repeated words in this do...   \n","\n","                                        count_vector  \\\n","0  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, ...   \n","1  [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, ...   \n","2  [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...   \n","3  [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n","\n","                                         probability  \n","0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666...  \n","1  [0.14285714285714285, 0.0, 0.14285714285714285...  \n","2  [0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.1...  \n","3  [0.0, 0.1111111111111111, 0.0, 0.1111111111111...  "]},"execution_count":230,"metadata":{},"output_type":"execute_result"}],"source":["def vocab(file):\n","    '''\n","    Input: txt file url\n","    Output: list of unique words in the file\n","    '''\n","\n","    if type(file) is pd.core.frame.DataFrame:\n","        df = file\n","        # Vocab from df unique words\n","        vocab = set()\n","        for text in df[\"Document\"]:\n","            # Taking care of symbols - only words are considered\n","            vocab.update(text.split(\" \"))\n","\n","        # Return as a list\n","        vocab = set(vocab)\n","        return(list(vocab))\n","    else: \n","        with open(file, 'r') as f:\n","            vocab = set(f.read().split())\n","            # Return as a list\n","        return(list(vocab))\n","\n","\n","\n","\n","def count_vector_n_probabilities(text, vocab):\n","    '''\n","    Input: text, vocab\n","    Output: list of counts of words in vocab\n","    '''\n","    count_vector = [0]*len(vocab)\n","    # Split the text into words\n","    words = text.split()\n","    # For each word - add 1 to the corresponding index\n","    for word in words:\n","        if word in vocab:\n","            count_vector[vocab.index(word)] += 1\n","            \n","    # Calculate the probability of each word\n","    total_words = len(words)\n","    probabilities = [count/total_words for count in count_vector]\n","    return(count_vector, probabilities)\n","\n","\n","\n","\n","def create_count_and_probability(file_name):\n","    '''\n","    Input: txt file url\n","    Output: CSV file with \"Text\", \"Count_Vector\", \"Probability\" columns\n","    '''\n","    df = pd.read_csv(file_name, sep='\\t', header=None)\n","    # Add a name to the column\n","    df.columns = [\"text\"]\n","    # Create a column with the count vector\n","    df[\"count_vector\"] = df[\"text\"].apply(lambda x: count_vector_n_probabilities(x, vocab(\"corpus.txt\"))[0])\n","    # Create a column with the probability\n","    df[\"probability\"] = df[\"text\"].apply(lambda x: count_vector_n_probabilities(x, vocab(\"corpus.txt\"))[1])\n","    # Save as a CSV file\n","    df.to_csv(\"count_vector_and_probability.csv\", index=False)\n","    \n","    return(df)\n","\n","df = create_count_and_probability(\"corpus.txt\")\n","df"]},{"cell_type":"markdown","id":"41c56eef-5e75-41b5-a05c-f68d0b7d98fd","metadata":{"id":"41c56eef-5e75-41b5-a05c-f68d0b7d98fd"},"source":["### Task 3 (8 points)\n","\n","The goal of this task is to train and test classifiers provided in scikit-learn, using two datasets `rural.txt` and `science.txt`.\n","\n","a) Each file (rural and science) contains sentence-wise documents. You should create a dataframe containing two columns: \"Document\" and \" Class\", as shown below. This dataframe will be used later as input for the vectorizer.\n","\n","|Document                             |Class |\n","| ------------------------------------|----- |\n","|PM denies knowledge of AWB kickbacks | rural |\n","|The crocodile ancestor fossil, found...| science |\n","\n","\n","b) Split the data into train (70%) and test (30%) sets and use the tf-idf-vectorizer to train following classifiers provided by scikit-learn:\n","\n","- naive_bayes.GaussianNB()\n","- svm.LinearSVC().\n","\n","c) Evaluate both classifiers using the test set, report accuracy, recall, precision, f1 scores and confusion matrix.\n","\n","**Hints:**\n","1. The Gaussian NB Classifier takes a dense matrix as input and the output of the vectorizer is a sparse matrix. Use my_matrix.toarray() for this conversion.\n","2. You can play around with various parameters in both the tf-idf-vectorizer and the classifier to get a better performance in terms of the accuracy. (In the exercise, we will discuss the accuracy of your model.)"]},{"cell_type":"code","execution_count":231,"id":"4f4b527a-0d04-4a0e-9281-fec9e0cd0ec0","metadata":{"id":"4f4b527a-0d04-4a0e-9281-fec9e0cd0ec0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Document</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Cystic fibrosis in Yellandu Khammam Hyderabad ...</td>\n","      <td>science</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Inhaling the mists of salt water can reduce th...</td>\n","      <td>science</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>That's the conclusion of two studies published...</td>\n","      <td>science</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>They found that inhaling a mist with a salt co...</td>\n","      <td>science</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Cystic fibrosis, a progressive and frequently ...</td>\n","      <td>science</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>445</th>\n","      <td>Hindmarsh mayor Darryl Argall says the taskfor...</td>\n","      <td>rural</td>\n","    </tr>\n","    <tr>\n","      <th>446</th>\n","      <td>Dairy companies compete for suppliers</td>\n","      <td>rural</td>\n","    </tr>\n","    <tr>\n","      <th>447</th>\n","      <td>Competition for milk suppliers is intensifying...</td>\n","      <td>rural</td>\n","    </tr>\n","    <tr>\n","      <th>448</th>\n","      <td>After years of dismal prices, milk company Fon...</td>\n","      <td>rural</td>\n","    </tr>\n","    <tr>\n","      <th>449</th>\n","      <td>Doug Chant from the Victorian Farmers Federati...</td>\n","      <td>rural</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1020 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                              Document    Class\n","0    Cystic fibrosis in Yellandu Khammam Hyderabad ...  science\n","1    Inhaling the mists of salt water can reduce th...  science\n","2    That's the conclusion of two studies published...  science\n","3    They found that inhaling a mist with a salt co...  science\n","4    Cystic fibrosis, a progressive and frequently ...  science\n","..                                                 ...      ...\n","445  Hindmarsh mayor Darryl Argall says the taskfor...    rural\n","446              Dairy companies compete for suppliers    rural\n","447  Competition for milk suppliers is intensifying...    rural\n","448  After years of dismal prices, milk company Fon...    rural\n","449  Doug Chant from the Victorian Farmers Federati...    rural\n","\n","[1020 rows x 2 columns]"]},"execution_count":231,"metadata":{},"output_type":"execute_result"}],"source":["rural_df = pd.read_csv(\"rural.txt\", header=None, sep=\"\\t\")\n","rural_df.columns = ['Document']\n","rural_df[\"Class\"] = \"rural\"\n","\n","science_df = pd.read_csv(\"science.txt\", header=None, sep=\"\\t\")\n","science_df.columns = ['Document']\n","science_df[\"Class\"] = \"science\"\n","\n","df = pd.concat([science_df, rural_df])\n","df"]},{"cell_type":"code","execution_count":232,"metadata":{},"outputs":[],"source":["# Splitting into testing and training\n","# Using scikit learn\n","from sklearn.model_selection import train_test_split\n","\n","\n","X = df[\"Document\"]\n","y = df[\"Class\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=0) # Use same random state for reproducibility\n"]},{"cell_type":"code","execution_count":233,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(714, 4000)\n","(306, 4000)\n"]}],"source":["# TF-IDF : Term Frequency - Inverse Document Frequency\n","\n","# TF(term, document) = (#term apperences/ # total terms in document) \n","# ITF(term, Corpus) = log(#Number of Docs in Corpus / # documents containing term + 1)\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","documents = df[\"Document\"]\n","\n","# Creating a TF-IDF vectorizer\n","vectorizer = TfidfVectorizer(max_features=4000, ngram_range=(1,2))\n","\n","# Making tf-idf matrix\n","tfidf_train = vectorizer.fit_transform(X_train)\n","tfidf_test = vectorizer.transform(X_test)\n","\n","# Print the shape of the matrices\n","print(tfidf_train.shape)\n","print(tfidf_test.shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["There is a difference in the vocab size - one based on simple split function  - other is built with the TF-IDF matrix from scikitlearn"]},{"cell_type":"code","execution_count":234,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:  0.9248366013071896\n","Recall:  0.9248366013071896\n","Precision:  0.9249137179049571\n","Confusion Matrix: \n"," [[131  13]\n"," [ 10 152]]\n"]}],"source":["\n","# Classification using GaussianNB\n","\n","from sklearn.naive_bayes import GaussianNB\n","\n","classifier = GaussianNB()\n","classifier.fit(tfidf_train.toarray(), y_train)\n","\n","# Predicting the Test set results\n","y_pred = classifier.predict(tfidf_test.toarray())\n","\n","# Accuracy\n","from sklearn.metrics import accuracy_score\n","accuracy_score = accuracy_score(y_test, y_pred)\n","print(\"Accuracy: \", accuracy_score)\n","# Recall and Precision\n","from sklearn.metrics import recall_score, precision_score\n","recall_score = recall_score(y_test, y_pred, average='weighted')\n","precision_score = precision_score(y_test, y_pred, average='weighted')\n","print(\"Recall: \", recall_score)\n","print(\"Precision: \", precision_score)\n","\n","# Making the Confusion Matrix\n","from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix: \\n\", cm)"]},{"cell_type":"code","execution_count":235,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:  0.9084967320261438\n","Recall:  0.9084967320261438\n","Precision:  0.912508261731659\n","Confusion Matrix: \n"," [[122  22]\n"," [  6 156]]\n"]}],"source":["# Classification using svm.LinearSVC()\n","\n","from sklearn.svm import LinearSVC\n","\n","classifier = LinearSVC()\n","classifier.fit(tfidf_train.toarray(), y_train)\n","\n","# Predicting the Test set results\n","y_pred = classifier.predict(tfidf_test.toarray())\n","\n","# Accuracy. Recall and Precision\n","from sklearn.metrics import accuracy_score, recall_score, precision_score\n","accuracy_score = accuracy_score(y_test, y_pred)\n","recall_score = recall_score(y_test, y_pred, average='weighted')\n","precision_score = precision_score(y_test, y_pred, average='weighted')\n","print(\"Accuracy: \", accuracy_score)\n","print(\"Recall: \", recall_score)\n","print(\"Precision: \", precision_score)\n","\n","# Making the Confusion Matrix\n","from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix: \\n\", cm)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":5}
